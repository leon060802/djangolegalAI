{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\NCU\\FirstSemester\\LegalAI\\django\\django-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸入文章: 五、如不服本裁定，應於裁定送達後10日內，以書狀向本院司法事務官提春異議。本案依法判決，合議庭審理完畢。\n",
      "修正後文章: 三、如不服本裁定，應於裁定送達後10日內，以書狀向本院司法事務官提出異議。本案依法判決，合議庭審理完畢。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, BertForMaskedLM\n",
    "from run_relm import PTuningWrapper\n",
    "\n",
    "def load_model_and_tokenizer(model_path, pretrained_model_path, prompt_length=1):\n",
    "    \"\"\"載入模型與 tokenizer\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_path)\n",
    "    base_model = BertForMaskedLM.from_pretrained(pretrained_model_path)\n",
    "    model = PTuningWrapper(base_model, prompt_length)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\"), weights_only=True))\n",
    "    model.eval()\n",
    "    return tokenizer, model\n",
    "\n",
    "def predict_sentence(sentence, tokenizer, model, prompt_length):\n",
    "    \"\"\"對單句進行模型推論與修正\"\"\"\n",
    "    # Tokenize sentence\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", max_length=128, padding=\"max_length\", truncation=True)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "    # 生成 prompt_mask\n",
    "    prompt_mask = torch.zeros_like(input_ids)\n",
    "    prompt_mask[:, :2 * prompt_length] = 1\n",
    "\n",
    "    # 模型推論\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, \n",
    "                        attention_mask=inputs[\"attention_mask\"], \n",
    "                        prompt_mask=prompt_mask,  \n",
    "                        apply_prompt=True)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "    # 解碼並清理 token\n",
    "    predicted_tokens = tokenizer.convert_ids_to_tokens(predictions[0])\n",
    "    input_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "    # 清理 token\n",
    "    return clean_tokens_with_numbers(input_tokens[1:], predicted_tokens[1:])\n",
    "\n",
    "def clean_tokens_with_numbers(input_tokens, predicted_tokens):\n",
    "    \"\"\"清理預測的 tokens，保留數字不變，處理 ## 拼接\"\"\"\n",
    "    clean_text = \"\"\n",
    "    for input_token, predicted_token in zip(input_tokens, predicted_tokens):\n",
    "        if input_token in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]:\n",
    "            continue\n",
    "        if input_token.isdigit() and predicted_token.isdigit() and input_token != predicted_token:\n",
    "            clean_text += input_token\n",
    "        elif predicted_token.startswith(\"##\"):\n",
    "            clean_text += predicted_token[2:]\n",
    "        else:\n",
    "            clean_text += predicted_token\n",
    "    return clean_text\n",
    "\n",
    "def process_article(article_text, tokenizer, model, prompt_length=1):\n",
    "    \"\"\"將文章分句並進行修正，輸出完整修正後的文章\"\"\"\n",
    "    sentences = [s + \"。\" for s in article_text.split(\"。\") if s]  # 分句並保留句號\n",
    "    corrected_sentences = []\n",
    "    for sentence in sentences:\n",
    "        corrected_sentence = predict_sentence(sentence, tokenizer, model, prompt_length)\n",
    "        corrected_sentences.append(corrected_sentence)\n",
    "    return \"\".join(corrected_sentences)\n",
    "\n",
    "# === 主程式 ===\n",
    "if __name__ == \"__main__\":\n",
    "    # 設定路徑\n",
    "    model_path = \"D:/NCU/FirstSemester/LegalAI/relm_autocorrection/Judgement_Process_Artical/step-10200_f1-76.67.bin\"  # 替換成你的模型權重路徑\n",
    "    pretrained_model_path = \"bert-base-chinese\"\n",
    "    prompt_length = 1\n",
    "\n",
    "    # 載入模型與 tokenizer\n",
    "    tokenizer, model = load_model_and_tokenizer(model_path, pretrained_model_path, prompt_length)\n",
    "\n",
    "    # 輸入文章字串\n",
    "    article_text = \"五、如不服本裁定，應於裁定送達後10日內，以書狀向本院司法事務官提春異議。本案依法判決，合議庭審理完畢。\"\n",
    "    \n",
    "    # 修正文章\n",
    "    corrected_article = process_article(article_text, tokenizer, model, prompt_length)\n",
    "    \n",
    "    # 輸出結果\n",
    "    print(\"輸入文章:\", article_text)\n",
    "    print(\"修正後文章:\", corrected_article)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "django-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
